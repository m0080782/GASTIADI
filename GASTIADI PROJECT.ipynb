{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of gastiadi_coba.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "TfCqBk0pwGH8",
        "v1LUR9y8wGID",
        "fRa0RPlCwGIE",
        "mW4H0ZmPwGIG",
        "PsDQe8QuwGIH",
        "hgzCZ3VzwGII",
        "1K0TUVTSwGIJ",
        "x3HhDZP9wGIJ",
        "XuH9Ck0iwGIK",
        "fHyJ6JcfwGIM",
        "51lOLBfSwGIN",
        "nXQUGl2owGIQ"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-1Q7M2hwGHe"
      },
      "source": [
        "# **GASTIADI PROJECT**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hfA-MQF5EnE"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/drive/19TMQXrycBhoJoWZcjAuHqd1EF-yexMlr?usp=sharing\">\n",
        "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/vitoatmo/gastiadi-project/blob/main/gastiadi.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "  <img src=\"https://img.shields.io/github/watchers/vitoatmo/gastiadi-project?style=social\" />\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwSxCavjKu9N"
      },
      "source": [
        "### Install the required packages\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6lKIEkIcD7W"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1Pehn8ScFXH"
      },
      "source": [
        "import numpy as np\n",
        "from numpy.random import RandomState\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing import sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqF2OBBZwGHh"
      },
      "source": [
        "### Prep work: Downloading necessary files\n",
        "Before we get started, we need to store all of the data we'll be using.\n",
        "* **sentiment500-subset.csv:** cleaned subset of Sentiment1000 data - as positive or negative\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHyiyYGKqeA3"
      },
      "source": [
        "import the data in session storage and then copy the path of each data \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8__7yX6r6Wlm"
      },
      "source": [
        "!git clone https://github.com/vitoatmo/gastiadi-project.git "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yk2gSJuDnFU"
      },
      "source": [
        "dataset = ('/content/gastiadi-project/dataset/datset_fix.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUZ31WkgwGHk"
      },
      "source": [
        "dataset= pd.read_csv(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTg4YhUU4UsW"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk1SsXehNHhu"
      },
      "source": [
        "dataset.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE2rDO6nC4Dp"
      },
      "source": [
        "print((dataset.Label == 1).sum()) #urgent\n",
        "print((dataset.Label == 0).sum()) #unurgent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryFctP4JEcP9"
      },
      "source": [
        "dataset.Text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EXI8w1gEf3b"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "#Count Unique Word\n",
        "\n",
        "def counter_word(text_col):\n",
        "    count = Counter()\n",
        "    for text in text_col.values:\n",
        "        for word in text.split():\n",
        "            count[word]+=1\n",
        "    return count\n",
        "  \n",
        "counter = counter_word(dataset.Text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMrZALNGFFBo"
      },
      "source": [
        "len(counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpkQeZMTwOCN"
      },
      "source": [
        "#Split Dataset Into Training and Validation Set\n",
        "import numpy\n",
        "train_size = int(dataset.shape[0]*0.8)\n",
        "\n",
        "train_ds = dataset[:train_size]\n",
        "val_ds = dataset[train_size:]\n",
        "\n",
        "#Split Text and Label\n",
        "train_sentences = train_ds.Text.to_numpy()\n",
        "train_labels = train_ds.Label.to_numpy()\n",
        "val_sentences = val_ds.Text.to_numpy()\n",
        "val_labels = val_ds.Label.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SryKeuDaHGKN"
      },
      "source": [
        "train_sentences.shape, val_sentences.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH_QhZgak1lc"
      },
      "source": [
        "#Tokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "#Vectorize a text corpus by turning each text into a sequence of integers\n",
        "num_unique_words=len(counter)\n",
        "tokenizer = Tokenizer(num_words=num_unique_words)\n",
        "tokenizer.fit_on_texts(train_sentences) #fit only to training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWu2qeCAwbGB"
      },
      "source": [
        "#each word has uniwue index\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhQyTdeOIS4A"
      },
      "source": [
        "word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNQIsmEFOdVJ"
      },
      "source": [
        "train_sentences=tokenizer.texts_to_sequences(train_sentences)\n",
        "val_sentences=tokenizer.texts_to_sequences(val_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ao5DKn-vkNQ"
      },
      "source": [
        "print(train_sentences[10:15])\n",
        "print(val_sentences[10:15])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huOz2xsLxKgu"
      },
      "source": [
        "#Pad the sequences to have the same length\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#Max number of words in a sequence\n",
        "max_length = 20\n",
        "\n",
        "train_padded =pad_sequences(train_sentences, maxlen=max_length, padding='post',truncating='post')\n",
        "val_padded =pad_sequences(val_sentences, maxlen=max_length, padding='post',truncating='post')\n",
        "train_padded.shape , val_padded.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRV9Z_1LxX8_"
      },
      "source": [
        "#Check the padding\n",
        "train_padded[10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgLqVksbqYqx"
      },
      "source": [
        "#Create Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(layers.Embedding(num_unique_words, 32, input_length=max_length))\n",
        "model.add(layers.LSTM(64, activation='relu', dropout=0.1))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3--uQO7OAZw"
      },
      "source": [
        "loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "optim = keras.optimizers.Adam(lr=0.01)\n",
        "metrics = ['accuracy']\n",
        "\n",
        "model.compile(loss= loss, optimizer=optim, metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uudXov_0PPdy"
      },
      "source": [
        "history = model.fit(train_padded, train_labels,epochs =20, validation_data=(val_padded,val_labels),verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhnJD_oQMO0e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "def plot_history(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_acc']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    x = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, acc, 'b', label='Training acc')\n",
        "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'b', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "  \n",
        "print(plot_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwEYZ_BrgDjz"
      },
      "source": [
        "model.evaluate(train_padded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V16ZSW_lavWS"
      },
      "source": [
        "predictions = model.predict(train_padded)\n",
        "predictions = [1 if p> 0.5 else 0 for p in predictions]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWPNkdVsbEwH"
      },
      "source": [
        "print(train_sentences[10:20])\n",
        "\n",
        "print(train_labels[10:20])\n",
        "print(predictions[10:20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G7ANIoer6XX"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "regressor = LinearRegression()\n",
        "\n",
        "#Fitting model with trainig data\n",
        "regressor.fit(train_padded, train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRLnM3mYnu6g"
      },
      "source": [
        "model.save(\"model_gastiadi\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIiXwnlEBD9L"
      },
      "source": [
        "import shutil\n",
        "shutil.make_archive('model_gastiadi', 'zip', 'model_gastiadi')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzPPsIHk_uGP"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/model_gastiadi.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}